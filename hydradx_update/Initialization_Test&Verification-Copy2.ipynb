{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "starting-salad",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "- Few Parameters (2x2) => 4 model runs\n",
    "- existing market pressure as the initial prices are not proportional to trade sizes\n",
    "- 5 LPs providing entirety of respective tokens (1-5) each\n",
    "- one trader executing random actions with probabilities:\n",
    "    - 'sell_r2_for_r1': 0.5,\n",
    "    - 'sell_r1_for_r2': 0,\n",
    "    - 'sell_r4_for_r3': 0.25,\n",
    "    - 'sell_r3_for_r4': 0.25\n",
    "- asset 5 is not affected by trader's actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-ocean",
   "metadata": {},
   "source": [
    "## Setup for initialization\n",
    "\n",
    "- Asset balances in the Omnipool:\n",
    "    - Asset 1: 7,000\n",
    "    - Asset 2: 90,000\n",
    "    - Asset 3: 13,000,000\n",
    "    - Asset 4: 8,300,000\n",
    "- LERNA balances in the Omnipool:\n",
    "    - Against Asset 1: 117,000,000\n",
    "    - Against Asset 2: 109,000,000\n",
    "    - Against Asset 3: 80,000,000\n",
    "    - Against Asset 4: 15,500,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eligible-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prepared-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset1 = 7000\n",
    "asset2 = 90000\n",
    "asset3 = 13000000\n",
    "asset4 = 8300000\n",
    "asset5 = 100000\n",
    "\n",
    "# reassign to 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adolescent-execution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    7000,    90000, 13000000,  8300000,   100000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_assets_in_pool = np.array([asset1, asset2, asset3, asset4, asset5])\n",
    "initial_assets_in_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "catholic-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "lerna1 = 117000000\n",
    "lerna2 = 109000000\n",
    "lerna3 = 80000000\n",
    "lerna4 = 15500000\n",
    "lerna5 = 100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unsigned-pierre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117000000, 109000000,  80000000,  15500000,    100000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_lerna_in_pool = np.array([lerna1, lerna2, lerna3, lerna4, lerna5])\n",
    "initial_lerna_in_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agreed-lotus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.67142857e+04, 1.21111111e+03, 6.15384615e+00, 1.86746988e+00,\n",
       "       1.00000000e+00])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_prices_in_pool = initial_lerna_in_pool / initial_assets_in_pool \n",
    "#initial_prices_in_pool = initial_assets_in_pool / initial_lerna_in_pool ## this is the WRONG one#\n",
    "## Changed for the purpose of 1:1 shares to asset ratios and consequently prices\n",
    "#initial_prices_in_pool = initial_assets_in_pool / initial_assets_in_pool \n",
    "## Changed for the purpose of 1:1 shares to asset ratios and consequently prices\n",
    "initial_prices_in_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "random-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_f['int'] = data_f['test'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-aaron",
   "metadata": {},
   "source": [
    "### calculate prices (denominated in LERNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unknown-staff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.67142857e+04, 1.21111111e+03, 6.15384615e+00, 1.86746988e+00,\n",
       "       1.00000000e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = lerna1 / asset1 \n",
    "p2 = lerna2 / asset2  \n",
    "p3 = lerna3 / asset3 \n",
    "p4 = lerna4 / asset4  \n",
    "p5 = lerna5 / asset5 \n",
    "prices = [p1, p2, p3, p4, p5]\n",
    "prices = initial_prices_in_pool\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unlimited-friendship",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from model.model_initialization import * \n",
    "#initialize_model([1000000, 1500000, 2000000, 2500000, 3000000], 100, 0.01, 0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distant-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### TEST INITIALIZATION ##########\n",
    "\n",
    "#########################################################\n",
    "#           import of packages & dependencies\n",
    "#########################################################\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.debugger import Pdb\n",
    "ipdb = Pdb()\n",
    "\n",
    "from model import init_utils\n",
    "from model import processing\n",
    "# Experiments\n",
    "from model import run\n",
    "from model.plot_utils import *\n",
    "from model.model_initialization import * \n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "#########################################################\n",
    "#     setting of experiment variables & parameters\n",
    "#########################################################\n",
    "\n",
    "# fee_levels_total = 0.005, 0.050\n",
    "# fee_level_assets = fee_levels_total / 2\n",
    "# fee_level_hdx = fee_levels_total / 2\n",
    "\n",
    "fee_level_assets = (0.0000, 0.0001, 0.0002, 0.0003, 0.0004) #10-50bps\n",
    "fee_level_assets = (0.0000, 0.0001)\n",
    "fee_level_hdx = 0.00\n",
    "# uniform_data = np.random.rand(10, 12)\n",
    "#trade_volume = {'10': 0.5, '20': 0.6}\n",
    "#liquidity = {'1000': 0.5, '2000': 0.6}\n",
    "#trade_volume = (50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000)\n",
    "#liquidity = (100000, 200000, 300000, 400000, 500000, 600000, 700000, 800000)\n",
    "trade_volume = [100, 110, 120]\n",
    "trade_volume = [1, 2] ##scale for reasonable size required\n",
    "#liquidity_providers = [1000000, 1500000, 2000000, 2500000, 3000000]\n",
    "liquidity_providers = initial_lerna_in_pool\n",
    "\n",
    "sim_nr = 0\n",
    "\n",
    "#########################################################\n",
    "#     specification of agent (for non-hard-coded calculations)\n",
    "#########################################################\n",
    "\n",
    "performance_of_agent = 'LP3'\n",
    "\n",
    "\n",
    "if performance_of_agent == 'LP1':\n",
    "    asset_of_agent = 'omniR1'\n",
    "elif performance_of_agent == 'LP2':\n",
    "    asset_of_agent = 'omniR2'\n",
    "elif performance_of_agent == 'LP3':\n",
    "    asset_of_agent = 'omniR3'\n",
    "\n",
    "#########################################################\n",
    "#     preparation of empty result matrix\n",
    "#########################################################\n",
    "\n",
    "m=len(trade_volume)\n",
    "n=len(fee_level_assets)\n",
    "matrix = np.ndarray(shape = (m,n), dtype = int)\n",
    "matrix1 = np.ndarray(shape = (m,n), dtype = int).astype('int64')\n",
    "matrix2 = np.ndarray(shape = (m,n), dtype = int).astype('int64')\n",
    "matrix3 = np.ndarray(shape = (m,n), dtype = int).astype('int64')\n",
    "matrix4 = np.ndarray(shape = (m,n), dtype = int).astype('int64')\n",
    "matrix5 = np.ndarray(shape = (m,n), dtype = int).astype('int64')\n",
    "matrix_ror = np.ndarray(shape = (m,n), dtype = int)\n",
    "matrix_ror1 = np.ndarray(shape = (m,n), dtype = float)\n",
    "matrix_ror2 = np.ndarray(shape = (m,n), dtype = float)\n",
    "matrix_ror3 = np.ndarray(shape = (m,n), dtype = float)\n",
    "matrix_ror4 = np.ndarray(shape = (m,n), dtype = float)\n",
    "matrix_ror5 = np.ndarray(shape = (m,n), dtype = float)\n",
    "\n",
    "\n",
    "#########################################################\n",
    "#     repeated simulation runs with above parameters\n",
    "#########################################################\n",
    "\n",
    "for i in range(len(fee_level_assets)):\n",
    "    for j in range(len(trade_volume)):\n",
    "#########################################################\n",
    "# initialize model with starting conditions for each run\n",
    "#########################################################\n",
    "\n",
    "        config_params = initialize_model(initial_lerna_in_pool, trade_volume[j], fee_level_assets[i], fee_level_hdx, initial_prices_in_pool, initial_assets_in_pool)\n",
    "\n",
    "#########################################################\n",
    "# run model with above initialization\n",
    "#########################################################\n",
    "\n",
    "        config_dict, state = init_utils.get_configuration(config_params)\n",
    "                                                  \n",
    "##### comment from here                                        \n",
    "####pd.options.mode.chained_assignment = None  # default='warn'\n",
    "####pd.options.display.float_format = '{:.2f}'.format\n",
    "####\n",
    "####run.config(config_dict, state)\n",
    "####events = run.run()\n",
    "####\n",
    "####rdf, agent_df = processing.postprocessing(events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "supposed-november",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'external': {},\n",
       " 'AMM': {'R': [7000, 90000, 13000000, 8300000, 100000],\n",
       "  'Q': [117000000.0, 109000000.0, 80000000.0, 15500000.0, 100000.0],\n",
       "  'S': [7000, 90000, 13000000, 8300000, 100000],\n",
       "  'A': [0, 0, 0, 0, 0],\n",
       "  'B': [-116993000, -108910000, -67000000, -7200000, 0],\n",
       "  'D': 0,\n",
       "  'T': None,\n",
       "  'H': None,\n",
       "  'token_list': ['R1', 'R2', 'R3', 'R4', 'R5'],\n",
       "  'fee_assets': 0.0001,\n",
       "  'fee_HDX': 0.0},\n",
       " 'uni_agents': {'Trader': {'q': 1000000,\n",
       "   's': [0, 0, 0, 0, 0],\n",
       "   'r': [1000000, 1000000, 1000000, 1000000, 1000000],\n",
       "   'p': [0, 0, 0, 0, 0]},\n",
       "  'LP1': {'q': 0,\n",
       "   's': [117000000, 0, 0, 0, 0],\n",
       "   'r': [0, 0, 0, 0, 0],\n",
       "   'p': [16714.285714285714, 0, 0, 0, 0]},\n",
       "  'LP2': {'q': 0,\n",
       "   's': [0, 109000000, 0, 0, 0],\n",
       "   'r': [0, 0, 0, 0, 0],\n",
       "   'p': [0, 1211.111111111111, 0, 0, 0]},\n",
       "  'LP3': {'q': 0,\n",
       "   's': [0, 0, 80000000, 0, 0],\n",
       "   'r': [0, 0, 0, 0, 0],\n",
       "   'p': [0, 0, 6.153846153846154, 0, 0]},\n",
       "  'LP4': {'q': 0,\n",
       "   's': [0, 0, 0, 15500000, 0],\n",
       "   'r': [0, 0, 0, 0, 0],\n",
       "   'p': [0, 0, 0, 1.8674698795180722, 0]},\n",
       "  'LP5': {'q': 0,\n",
       "   's': [0, 0, 0, 0, 100000],\n",
       "   'r': [0, 0, 0, 0, 0],\n",
       "   'p': [0, 0, 0, 0, 1.0]}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "express-lecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 1,\n",
       " 'T': range(0, 120),\n",
       " 'M': {'action_list': [['sell_r4_for_r3',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r2_for_r1',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r3_for_r4',\n",
       "    'sell_r1_for_r2',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r4_for_r3',\n",
       "    'sell_r2_for_r1']],\n",
       "  'action_dict': [{'sell_r2_for_r1': {'token_buy': 'R1',\n",
       "     'token_sell': 'R2',\n",
       "     'amount_sell': 3600,\n",
       "     'action_id': 'Trade',\n",
       "     'agent_id': 'Trader'},\n",
       "    'sell_r1_for_r2': {'token_sell': 'R1',\n",
       "     'token_buy': 'R2',\n",
       "     'amount_sell': 5.072174738841405,\n",
       "     'action_id': 'Trade',\n",
       "     'agent_id': 'Trader'},\n",
       "    'sell_r4_for_r3': {'token_buy': 'R3',\n",
       "     'token_sell': 'R4',\n",
       "     'amount_sell': 273508.68486352364,\n",
       "     'action_id': 'Trade',\n",
       "     'agent_id': 'Trader'},\n",
       "    'sell_r3_for_r4': {'token_sell': 'R3',\n",
       "     'token_buy': 'R4',\n",
       "     'amount_sell': 390000,\n",
       "     'action_id': 'Trade',\n",
       "     'agent_id': 'Trader'}}],\n",
       "  'timesteps': [120]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bottom-consolidation",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stophere' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-88d56cf18612>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstophere\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stophere' is not defined"
     ]
    }
   ],
   "source": [
    "stophere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e2d21-c455-4b2b-a1c4-0c2cce0fb286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#           import of packages & dependencies\n",
    "#########################################################\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.debugger import Pdb\n",
    "ipdb = Pdb()\n",
    "\n",
    "from model import init_utils\n",
    "from model import processing\n",
    "# Experiments\n",
    "from model import run\n",
    "from model.plot_utils import *\n",
    "from model.model_initialization import * \n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "#########################################################\n",
    "#     setting of experiment variables & parameters\n",
    "#########################################################\n",
    "\n",
    "# fee_levels_total = 0.005, 0.050\n",
    "# fee_level_assets = fee_levels_total / 2\n",
    "# fee_level_hdx = fee_levels_total / 2\n",
    "\n",
    "fee_level_assets = (0.0000, 0.0001, 0.0002, 0.0003, 0.0004) #10-50bps\n",
    "fee_level_assets = (0.0000, 0.0001)\n",
    "fee_level_hdx = 0.00\n",
    "# uniform_data = np.random.rand(10, 12)\n",
    "#trade_volume = {'10': 0.5, '20': 0.6}\n",
    "#liquidity = {'1000': 0.5, '2000': 0.6}\n",
    "#trade_volume = (50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000)\n",
    "#liquidity = (100000, 200000, 300000, 400000, 500000, 600000, 700000, 800000)\n",
    "trade_volume = [100, 110, 120]\n",
    "trade_volume = [1, 2] ##scale for reasonable size required\n",
    "#liquidity_providers = [1000000, 1500000, 2000000, 2500000, 3000000]\n",
    "liquidity_providers = initial_lerna_in_pool\n",
    "\n",
    "sim_nr = 0\n",
    "\n",
    "#########################################################\n",
    "#     specification of agent (for non-hard-coded calculations)\n",
    "#########################################################\n",
    "\n",
    "performance_of_agent = 'LP3'\n",
    "\n",
    "\n",
    "if performance_of_agent == 'LP1':\n",
    "    asset_of_agent = 'omniR1'\n",
    "elif performance_of_agent == 'LP2':\n",
    "    asset_of_agent = 'omniR2'\n",
    "elif performance_of_agent == 'LP3':\n",
    "    asset_of_agent = 'omniR3'\n",
    "\n",
    "#########################################################\n",
    "#     preparation of empty result matrix\n",
    "#########################################################\n",
    "\n",
    "m=len(trade_volume)\n",
    "n=len(fee_level_assets)\n",
    "matrix = np.ndarray(shape = (m,n), dtype = int)\n",
    "matrix1 = np.ndarray(shape = (m,n), dtype = int).astype('int64')\n",
    "matrix2 = np.ndarray(shape = (m,n), dtype = int).astype('int64')\n",
    "matrix3 = np.ndarray(shape = (m,n), dtype = int).astype('int64')\n",
    "matrix4 = np.ndarray(shape = (m,n), dtype = int).astype('int64')\n",
    "matrix5 = np.ndarray(shape = (m,n), dtype = int).astype('int64')\n",
    "matrix_ror = np.ndarray(shape = (m,n), dtype = int)\n",
    "matrix_ror1 = np.ndarray(shape = (m,n), dtype = float)\n",
    "matrix_ror2 = np.ndarray(shape = (m,n), dtype = float)\n",
    "matrix_ror3 = np.ndarray(shape = (m,n), dtype = float)\n",
    "matrix_ror4 = np.ndarray(shape = (m,n), dtype = float)\n",
    "matrix_ror5 = np.ndarray(shape = (m,n), dtype = float)\n",
    "\n",
    "\n",
    "#########################################################\n",
    "#     repeated simulation runs with above parameters\n",
    "#########################################################\n",
    "\n",
    "\n",
    "for i in range(len(fee_level_assets)):\n",
    "    for j in range(len(trade_volume)):\n",
    "        #########################################################\n",
    "        # initialize model with starting conditions for each run\n",
    "        #########################################################\n",
    "        \n",
    "        config_params = initialize_model(initial_lerna_in_pool, trade_volume[j], fee_level_assets[i], fee_level_hdx, initial_prices_in_pool, initial_assets_in_pool)\n",
    "        \n",
    "        #########################################################\n",
    "        # run model with above initialization\n",
    "        #########################################################\n",
    "        \n",
    "        config_dict, state = init_utils.get_configuration(config_params)\n",
    "\n",
    "        pd.options.mode.chained_assignment = None  # default='warn'\n",
    "        pd.options.display.float_format = '{:.2f}'.format\n",
    "        \n",
    "        run.config(config_dict, state)\n",
    "        events = run.run()\n",
    "        \n",
    "        rdf, agent_df = processing.postprocessing(events)\n",
    "\n",
    "        #########################################################\n",
    "        # calculate profitability metrics; change in pool values\n",
    "        #########################################################\n",
    "        \n",
    "         \n",
    "        print(sim_nr)\n",
    "        total_timesteps = config_params.get('action_ls')[0][1] #grabbing the same total timestep as through initialize_model\n",
    "        #total_timesteps = 1000\n",
    "        first_timestep = 1\n",
    "        print(total_timesteps)\n",
    "        \n",
    "        ## merge agent and pool dataframes\n",
    "        profit_results = pd.merge(agent_df, rdf, how=\"inner\", on=[\"timestep\", \"simulation\", \"run\", \"subset\", \"substep\"])\n",
    "        \n",
    "        ## assign additional columns\n",
    "        profit_results['val_pool'] = profit_results.apply(lambda x: processing.val_pool(x), axis=1)\n",
    "        initial_values = config_params['initial_values']\n",
    "        agent_d = config_params['agent_d']\n",
    "        withdraw_agent_d = processing.get_withdraw_agent_d(initial_values, agent_d)\n",
    "        print(withdraw_agent_d)\n",
    "        profit_results['val_hold'] = profit_results.apply(lambda x: processing.val_hold(x, withdraw_agent_d), axis=1)\n",
    "        #profit_results['IL'] = profit_results.apply(lambda x: x['val_pool']/x['val_hold'] - 1, axis=1)\n",
    "        profit_results['pool_val'] = profit_results.apply(lambda x: processing.pool_val(x), axis=1)\n",
    "        \n",
    "        ## calculate profits from 'val_pool' for initialized agent     \n",
    "        profit_results1 = profit_results[profit_results['simulation'] == sim_nr]\n",
    "        profit_results2 = profit_results1[profit_results1['timestep'] == total_timesteps]\n",
    "        profit_results3 = profit_results1[profit_results1['timestep'] == first_timestep]\n",
    "        profit_results4 = profit_results2[profit_results2['agent_label'] == performance_of_agent] #define selection for final timestep for desired agent (LP1 / LP2 / ??)\n",
    "        profit_results5 = profit_results3[profit_results3['agent_label'] == performance_of_agent] #define selection for first timestep for desired agent (LP1 / LP2 / ??)\n",
    " \n",
    "        ## calculate profits from 'val_pool' for hardcored agents (workaround)\n",
    "        profit_results41 = profit_results2[profit_results2['agent_label'] == 'LP1']\n",
    "        profit_results51 = profit_results3[profit_results3['agent_label'] == 'LP1']\n",
    "        profit_results42 = profit_results2[profit_results2['agent_label'] == 'LP2']\n",
    "        profit_results52 = profit_results3[profit_results3['agent_label'] == 'LP2']\n",
    "        profit_results43 = profit_results2[profit_results2['agent_label'] == 'LP3']\n",
    "        profit_results53 = profit_results3[profit_results3['agent_label'] == 'LP3']\n",
    "        profit_results44 = profit_results2[profit_results2['agent_label'] == 'LP4']\n",
    "        profit_results54 = profit_results3[profit_results3['agent_label'] == 'LP4']\n",
    "        profit_results45 = profit_results2[profit_results2['agent_label'] == 'LP5']\n",
    "        profit_results55 = profit_results3[profit_results3['agent_label'] == 'LP5']\n",
    "        \n",
    "        profit_sim0 = profit_results4['val_pool'].iloc[0] - profit_results5['val_pool'].iloc[0] # \n",
    "        profit_sim1 = profit_results41['val_pool'].iloc[0] - profit_results51['val_pool'].iloc[0] # profit for LP1\n",
    "        profit_sim2 = profit_results42['val_pool'].iloc[0] - profit_results52['val_pool'].iloc[0] # profit for LP2\n",
    "        profit_sim3 = profit_results43['val_pool'].iloc[0] - profit_results53['val_pool'].iloc[0] # profit for LP3\n",
    "        profit_sim4 = profit_results44['val_pool'].iloc[0] - profit_results54['val_pool'].iloc[0] # profit for LP2\n",
    "        profit_sim5 = profit_results45['val_pool'].iloc[0] - profit_results55['val_pool'].iloc[0] # profit for LP3\n",
    "        \n",
    "        ## calculate 'rate of return' in basispoints\n",
    "        ror0 = (profit_sim0 / agent_d[performance_of_agent][asset_of_agent]) * 100\n",
    "        ror1 = (profit_sim1 / agent_d['LP1']['omniR1']) * 100 # RoR for LP1 in %\n",
    "        ror2 = (profit_sim2 / agent_d['LP2']['omniR2']) * 100 # RoR for LP2 in %\n",
    "        ror3 = (profit_sim3 / agent_d['LP3']['omniR3']) * 100 # RoR for LP3 in %\n",
    "        ror4 = (profit_sim4 / agent_d['LP4']['omniR4']) * 100 # RoR for LP4 in %\n",
    "        ror5 = (profit_sim5 / agent_d['LP5']['omniR5']) * 100 # RoR for LP5 in %\n",
    "                    \n",
    "        #########################################################\n",
    "        # assign metrics (profit, ror) to empty matrix\n",
    "        #########################################################\n",
    "        \n",
    "        #matrix[j][i] = np.random.randint(1, 100 + 1)\n",
    "        #matrix[j][i] = trade_volume[i]*liquidity[j]\n",
    "        matrix[j][i] = profit_sim0\n",
    "        matrix1[j][i] = profit_sim1\n",
    "        matrix2[j][i] = profit_sim2\n",
    "        matrix3[j][i] = profit_sim3\n",
    "        matrix4[j][i] = profit_sim4\n",
    "        matrix5[j][i] = profit_sim5\n",
    "        #matrix1[j][i] = profit_sim1\n",
    "        matrix_ror[j][i] = ror0\n",
    "        matrix_ror1[j][i] = ror1\n",
    "        matrix_ror2[j][i] = ror2\n",
    "        matrix_ror3[j][i] = ror3\n",
    "        matrix_ror4[j][i] = ror4\n",
    "        matrix_ror5[j][i] = ror5\n",
    "        #matrix_ror1[j][i] = ror1\n",
    "        \n",
    "        #########################################################\n",
    "        ## increase simulation count\n",
    "        #########################################################\n",
    "        \n",
    "        sim_nr += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-frame",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-pizza",
   "metadata": {},
   "source": [
    "### Absolute Returns for LPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_labels = fee_level_assets\n",
    "y_axis_labels = trade_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-method",
   "metadata": {},
   "source": [
    "### Selected Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-logan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".0f\")\n",
    "ax.set_title(\"Total LP Profit \")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-blade",
   "metadata": {},
   "source": [
    "### LP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix1, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".0f\")\n",
    "ax.set_title(\"Total LP Profit \")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-mambo",
   "metadata": {},
   "source": [
    "### LP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix2, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".0f\")\n",
    "ax.set_title(\"Total LP Profit \")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-sleep",
   "metadata": {},
   "source": [
    "### LP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-detective",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix3, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".0f\")\n",
    "ax.set_title(\"Total LP Profit \")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-development",
   "metadata": {},
   "source": [
    "### LP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix4, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".0f\")\n",
    "ax.set_title(\"Total LP Profit \")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-fairy",
   "metadata": {},
   "source": [
    "### LP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".0f\")\n",
    "ax.set_title(\"Total LP Profit \")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-bridge",
   "metadata": {},
   "source": [
    "## Relative Returns for LPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-cycling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_ror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-compatibility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-saint",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix_ror, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".4f\")\n",
    "ax.set_title(\"LP Profits\")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-consideration",
   "metadata": {},
   "source": [
    "### LP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix_ror1, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".4f\")\n",
    "ax.set_title(\"Rate of Return for LP 1 in %\")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-stability",
   "metadata": {},
   "source": [
    "### LP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix_ror2, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".4f\")\n",
    "ax.set_title(\"Rate of Return for LP 2 in %\")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-sequence",
   "metadata": {},
   "source": [
    "### LP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-drove",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix_ror3, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".4f\")\n",
    "ax.set_title(\"Rate of Return for LP 3 in %\")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-indication",
   "metadata": {},
   "source": [
    "### LP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix_ror4, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".4f\")\n",
    "ax.set_title(\"Rate of Return for LP 4 in %\")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-begin",
   "metadata": {},
   "source": [
    "### LP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-saudi",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
    "ax = sns.heatmap(matrix_ror5, xticklabels=x_axis_labels, yticklabels=y_axis_labels, linewidth=0.5, annot=True, fmt=\".4f\")\n",
    "ax.set_title(\"Rate of Return for LP 5 in %\")\n",
    "#ax.set_title(\"LP Profits for fee level:\" % fee_level)\n",
    "ax.set_xlabel('Fee Level')\n",
    "ax.set_ylabel('Trade Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import plot_utils as pu\n",
    "varlist = ['val_pool']\n",
    "dataframe = profit_results[profit_results['simulation'] == 0]\n",
    "dataframe = dataframe[dataframe['substep'] == 3]\n",
    "dataframe = dataframe[dataframe['run'] == 1]\n",
    "#dataframe = dataframe[dataframe['agent_label'] == 'LP4']\n",
    "pu.plot_vars(dataframe, varlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_results['Q-0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_results['R-0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_results.columns.unique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
